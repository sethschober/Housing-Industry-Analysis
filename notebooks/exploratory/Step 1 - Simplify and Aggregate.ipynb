{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os, sys\n",
    "\n",
    "path_to_src = os.path.join('..', '..', 'src')\n",
    "sys.path.insert(1, path_to_src)\n",
    "from custom_functions import *\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import datasets and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import lookups dictionary\n",
    "path = os.path.join('..','..', 'data', 'raw', 'EXTR_LookUp.csv')\n",
    "df_lookup = pd.read_csv(path, dtype='str')\n",
    "\n",
    "# Import Buildings database\n",
    "path = os.path.join('..','..', 'data', 'raw', 'EXTR_ResBldg.csv')\n",
    "df_resbldg = pd.read_csv(path, dtype='str')\n",
    "\n",
    "# Import Sales database\n",
    "path = os.path.join('..','..', 'data', 'raw', 'EXTR_RpSale.csv')\n",
    "df_rpsale = pd.read_csv(path, dtype='str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Strip leading and trailing spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lookup = strip_spaces(df_lookup)\n",
    "df_resbldg = strip_spaces(df_resbldg)\n",
    "df_rpsale = strip_spaces(df_rpsale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Drop columns that are obviously unnecessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "resbldg_desired = ['Major', 'Minor', 'NbrLivingUnits', 'Stories', 'BldgGrade', \n",
    "                   'BldgGradeVar', 'SqFt1stFloor', 'SqFtHalfFloor', \n",
    "                   'SqFt2ndFloor','SqFtUpperFloor', 'SqFtUnfinFull', \n",
    "                   'SqFtUnfinHalf', 'SqFtTotLiving', 'SqFtTotBasement', \n",
    "                   'SqFtFinBasement', 'FinBasementGrade', 'SqFtGarageBasement', \n",
    "                   'SqFtGarageAttached', 'DaylightBasement','SqFtOpenPorch', \n",
    "                   'SqFtEnclosedPorch', 'SqFtDeck', 'HeatSystem','HeatSource', \n",
    "                   'BrickStone', 'ViewUtilization', 'Bedrooms','BathHalfCount', \n",
    "                   'Bath3qtrCount', 'BathFullCount', 'FpSingleStory',\n",
    "                   'FpMultiStory', 'FpFreestanding', 'FpAdditional', 'YrBuilt',\n",
    "                   'YrRenovated', 'PcntComplete', 'Obsolescence', \n",
    "                   'PcntNetCondition','Condition']\n",
    "df_resbldg = df_resbldg[resbldg_desired].copy()\n",
    "\n",
    "rpsale_desired = ['ExciseTaxNbr', 'Major', 'Minor', 'DocumentDate', \n",
    "                  'RecordingNbr', 'PropertyType', 'PrincipalUse', \n",
    "                  'SaleInstrument', 'AFForestLand', 'AFCurrentUseLand', \n",
    "                  'AFNonProfitUse', 'AFHistoricProperty', 'SaleReason', \n",
    "                  'SalePrice', 'PropertyClass', 'SaleWarning']\n",
    "df_rpsale = df_rpsale[rpsale_desired].copy()\n",
    "\n",
    "# Create ParcelIDs\n",
    "df_rpsale['Parcel_ID'] = df_rpsale.Major + '-' + df_rpsale.Minor\n",
    "df_resbldg['Parcel_ID'] = df_resbldg.Major + '-' + df_resbldg.Minor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refine *Sales* DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Eliminate irrelevant property types, non-2019 sales, and add necessary helper columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only sales for \"Residential\" plots, corresponding to code #6, \n",
    "# as can be found in the data dictionary. This eliminates:\n",
    "# Commerical, Condominium, Apartment, etc.\n",
    "df_rpsale['PrincipalUse'] = elimination_by_code(df_rpsale['PrincipalUse'], '6')\n",
    "\n",
    "# PropertyClass is another distinction between Commerical/Industrial\n",
    "# and Residential, as well as other fundamental features. \n",
    "# Code #8 corresponds to Residential Improved property\n",
    "df_rpsale['PropertyClass'] = elimination_by_code(df_rpsale['PropertyClass'], '8')\n",
    "\n",
    "# Yet another classification of property type. Code #11 corresponds \n",
    "# to single family households. Here we eliminate multiple family residences, \n",
    "# alongside many commercial uses\n",
    "df_rpsale['PropertyType'] = elimination_by_code(df_rpsale['PropertyType'], '11')\n",
    "df_rpsale.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Eliminate non-2019 sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'res_sales' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-2a5c32e31ace>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mres_sales\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'DocumentDate'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres_sales\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDocumentDate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mres_sales\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SaleYear'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msale\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myear\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msale\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mres_sales\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'DocumentDate'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mres_sales\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres_sales\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mres_sales\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SaleYear'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m2019\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'res_sales' is not defined"
     ]
    }
   ],
   "source": [
    "res_sales['DocumentDate'] = res_sales.DocumentDate.astype(np.datetime64)\n",
    "res_sales['SaleYear'] = [sale.year for sale in res_sales['DocumentDate']]\n",
    "res_sales = res_sales.loc[res_sales['SaleYear']==2019].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Eliminate unrealistically small sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_acceptable_sale_price = 25000\n",
    "res_sales['SalePrice'] = res_sales.SalePrice.astype('int')\n",
    "res_sales = res_sales.loc[res_sales.SalePrice > min_acceptable_sale_price].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop sales determined to be invalid\n",
    "res_sales.dropna(inplace=True)\n",
    "\n",
    "# Create column to identify duplicates\n",
    "res_sales['SaleCount'] = list(map(dict(res_sales.Parcel_ID.\n",
    "                                       value_counts()).get, \n",
    "                                  res_sales.Parcel_ID))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove sales for a given property that are not the most recent**\n",
    "\n",
    "This prevents re-sale of homes from counting for multiple entries, which would overrepresent homes that tend to be resold within the final model. More importantly, it is a necessary step in order to join the Sales database with the Residential Building database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_latest_sale(docdates, parcel_ids):\n",
    "    latest_parcel_sale = []\n",
    "    data = pd.DataFrame([docdates, parcel_ids]).T\n",
    "    data.DocumentDate = data.DocumentDate.astype('datetime64')\n",
    " \n",
    "    for i, parcel_id in enumerate(data.Parcel_ID):\n",
    "        relevant_docdates = data.loc[data.Parcel_ID == parcel_id, 'DocumentDate']\n",
    "        max_docdate = relevant_docdates.values.max()\n",
    "        \n",
    "        this_datetime = np.datetime64(data.iloc[i, 0]) \n",
    "        latest_parcel_sale.append(this_datetime == max_docdate)\n",
    "\n",
    "    return latest_parcel_sale\n",
    "\n",
    "tf = identify_latest_sale(res_sales.DocumentDate, res_sales.Parcel_ID)\n",
    "latest_sales = res_sales.loc[tf].copy()\n",
    "latest_sales['SaleCount'] = list(map(dict(latest_sales.Parcel_ID.\n",
    "                                          value_counts()).get, \n",
    "                                     latest_sales.Parcel_ID))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Determine average price for multiple sales on the same day on the same parcel**\n",
    "\n",
    "This is a necessary step to joining the Sales database with the Residential Building database by removing duplicate entries without losing the valuable sales price data that would be lost by dropping a duplicate at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_price_for_duped_parcels(data):\n",
    "    dupes = data.loc[data.SaleCount > 1]\n",
    "    for i, ind in enumerate(dupes.index):\n",
    "        parcel_id = data.loc[ind, 'Parcel_ID']\n",
    "        parcels_w_parcel_id = data.loc[data.Parcel_ID == parcel_id, 'SalePrice']\n",
    "\n",
    "        avg_price_for_id = parcels_w_parcel_id.values.mean()\n",
    "        for parcel_index in parcels_w_parcel_id.index:\n",
    "            data.at[parcel_index, 'SalePrice'] = avg_price_for_id\n",
    "    return data\n",
    "\n",
    "# Average pricing for duplicates\n",
    "latest_sales_averaged = avg_price_for_duped_parcels(latest_sales)\n",
    "latest_sales_averaged['SaleCount'] = list(map(dict(latest_sales_averaged.\n",
    "                                                   Parcel_ID.value_counts()).get, \n",
    "                                              latest_sales_averaged.Parcel_ID))\n",
    "\n",
    "\n",
    "# Remove duplicates\n",
    "latest_sales_averaged.index = latest_sales_averaged.Parcel_ID.values\n",
    "latest_sales_averaged_deduped = latest_sales_averaged.drop_duplicates('Parcel_ID')\n",
    "latest_sales_averaged_deduped.reset_index(inplace=True, drop=True)\n",
    "latest_sales_averaged_deduped.index = latest_sales_averaged_deduped.Parcel_ID.values\n",
    "\n",
    "\n",
    "# Drop unused columns as final step of cleaning before join\n",
    "latest_sales_averaged_deduped_tokeep = ['SalePrice', 'Parcel_ID', 'PropertyType', \n",
    "                                        'PrincipalUse', 'SaleInstrument', \n",
    "                                        'AFForestLand', 'AFCurrentUseLand', \n",
    "                                        'AFNonProfitUse', 'AFHistoricProperty', \n",
    "                                        'SaleReason', 'PropertyClass', 'SaleWarning']\n",
    "sales = latest_sales_averaged_deduped[latest_sales_averaged_deduped_tokeep].copy()\n",
    "sales['SaleInstrument'] = sales.SaleInstrument.astype('int64')\n",
    "\n",
    "sales.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle Residential Building dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic preparation of residential building database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_int = ['SqFtOpenPorch', 'SqFtEnclosedPorch', 'Bedrooms', \n",
    "                  'SqFtGarageAttached', 'SqFtGarageBasement', 'NbrLivingUnits', \n",
    "                  'BldgGrade', 'SqFt1stFloor','SqFtHalfFloor', 'SqFt2ndFloor', \n",
    "                  'SqFtUpperFloor', 'SqFtUnfinFull', 'SqFtUnfinHalf',\n",
    "                  'SqFtTotLiving', 'SqFtTotBasement', 'SqFtFinBasement', \n",
    "                  'FinBasementGrade', 'SqFtGarageBasement', 'SqFtGarageAttached', \n",
    "                  'SqFtOpenPorch', 'SqFtEnclosedPorch', 'SqFtDeck', \n",
    "                  'BathHalfCount', 'Bath3qtrCount', 'BathFullCount', \n",
    "                  'FpSingleStory', 'FpMultiStory', 'FpFreestanding', \n",
    "                  'FpAdditional', 'YrBuilt', 'YrRenovated', 'BrickStone']\n",
    "for category in convert_to_int:\n",
    "    df_resbldg[category] = df_resbldg[category].astype('int')\n",
    "    \n",
    "convert_to_float = ['Stories']\n",
    "for category in convert_to_float:\n",
    "    df_resbldg[category] = df_resbldg[category].astype('float')\n",
    "    \n",
    "# Nit-picky\n",
    "# Data cleaning for inconsistent casing\n",
    "df_resbldg['DaylightBasement'] = df_resbldg['DaylightBasement'].str.upper() \n",
    "\n",
    "# Remove buildings that aren't complete\n",
    "df_resbldg = df_resbldg.loc[df_resbldg.PcntComplete.astype('str') == '0'].copy() \n",
    "\n",
    "# Remove buildings in obsolescence process\n",
    "df_resbldg = df_resbldg.loc[df_resbldg.Obsolescence.astype('str') == '0'].copy() \n",
    "\n",
    "# Remove 6 outliers in abnormal condition\n",
    "df_resbldg = df_resbldg.loc[df_resbldg.PcntNetCondition.astype('str') == '0'].copy() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join with SQL and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_db = os.path.join('..', '..', 'data', 'processed', 'main.db')\n",
    "conn = sqlite3.connect(path_to_db)\n",
    "df_resbldg.to_sql('buildings', conn, if_exists='replace')\n",
    "sales.to_sql('sales', conn, if_exists='replace')\n",
    "\n",
    "q = ''' SELECT * FROM buildings\n",
    "LEFT JOIN sales USING (Parcel_ID)'''\n",
    "\n",
    "joined = pd.read_sql(q, conn)\n",
    "\n",
    "\n",
    "keepers = ['SalePrice', 'NbrLivingUnits', 'Stories', 'BldgGrade', \n",
    "           'SqFt1stFloor', 'SqFtHalfFloor', 'SqFt2ndFloor', 'SqFtUpperFloor', \n",
    "           'SqFtUnfinFull', 'SqFtUnfinHalf', 'SqFtTotLiving', 'SqFtTotBasement', \n",
    "           'SqFtFinBasement', 'FinBasementGrade', 'SqFtGarageBasement', \n",
    "           'SqFtGarageAttached', 'DaylightBasement', 'SqFtOpenPorch', \n",
    "           'SqFtEnclosedPorch', 'SqFtDeck', 'HeatSystem', 'HeatSource', \n",
    "           'BrickStone', 'ViewUtilization', 'Bedrooms', 'BathHalfCount', \n",
    "           'Bath3qtrCount', 'BathFullCount', 'FpSingleStory', 'FpMultiStory', \n",
    "           'FpFreestanding', 'FpAdditional', 'YrBuilt',  'YrRenovated', \n",
    "           'Condition', 'SaleInstrument']\n",
    "df_main = joined[keepers].copy()\n",
    "\n",
    "\n",
    "df_main.dropna(inplace=True)\n",
    "df_main.reset_index(inplace=True, drop=True)\n",
    "\n",
    "df_main['SalePrice'] = df_main['SalePrice'].astype('int64')\n",
    "df_main['SaleInstrument'] = df_main['SaleInstrument'].astype('int64')\n",
    "\n",
    "YN_converter = lambda x: 1 if ((x == 'Y')|(x==1)) else \n",
    "                         0 if ((x == 'N')|(x==0)) else np.nan\n",
    "\n",
    "# NOTE THAT THESE CAUSES LOTS OF NA'S!\n",
    "df_main.DaylightBasement = df_main.DaylightBasement.apply(YN_converter) \n",
    "df_main.ViewUtilization = df_main.ViewUtilization.apply(YN_converter)\n",
    "\n",
    "# Store primary dataframe in SQL database\n",
    "df_main.to_sql('step1_aggregated', conn, if_exists='replace')\n",
    "\n",
    "\n",
    "# Store the lookup codes in the SQL database in case they are needed downstream\n",
    "df_lookup.to_sql('lookups', conn, if_exists='replace')\n",
    "\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
