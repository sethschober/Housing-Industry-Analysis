{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This analysis seeks to gather and prove valuable observations about the impact of various home attributes on its value. The project combines multiple publicly available datasets [made available](https://data.kingcounty.gov/) by King County. One dataset provides a record of home and land sales alongside various identifying feautres. The second dataset gives very granular data about housing in King County, going beyond just square footage to a breakdown by room, many identifying features such as porch size, and more. Combining these two datasets opens the door for the analysis to come. \n",
    "\n",
    "This notebook provides a somewhat condensed analysis compared to the full sequence necessary to understand the full details of choosing specific models and the nitty-gritty details. Please refer to the notebooks in the repository folder notebooks->exploratory if you would like to see a deep dive.\n",
    "\n",
    "### The Process\n",
    "1. Basic Setup and Data Assembly\n",
    "2. Data Aggregation and Cleaning\n",
    "3. Feature Selection and Creation\n",
    "4. The Model\n",
    "5. The Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Setup and Data Assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os, sys\n",
    "\n",
    "# Import functions from a Python file in this repository with context-relevant functionality\n",
    "path_to_src = os.path.join('..', '..', 'src')\n",
    "sys.path.insert(1, path_to_src)\n",
    "from custom_functions import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import King County housing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv files from the data directory\n",
    "df_lookup = pd.read_csv(os.path.join('..','..', 'data', 'raw', 'EXTR_LookUp.csv'), dtype='str')\n",
    "df_resbldg = pd.read_csv(os.path.join('..','..', 'data', 'raw', 'EXTR_ResBldg.csv'), dtype='str')\n",
    "df_rpsale = pd.read_csv(os.path.join('..','..', 'data', 'raw', 'EXTR_RpSale.csv'), dtype='str')\n",
    "\n",
    "# Use the user-defined strip_spaces function to remove leading and trailing spaces from the entire dataframe\n",
    "df_lookup = strip_spaces(df_lookup)\n",
    "df_resbldg = strip_spaces(df_resbldg)\n",
    "df_rpsale = strip_spaces(df_rpsale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Eliminate unecessary data. After close investigation, the below columns were deemed the most worthy of continued analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual selection of the features of choice\n",
    "resbldg_desired_columns = ['Major', 'Minor', 'NbrLivingUnits', 'Stories', 'BldgGrade', \n",
    "                           'BldgGradeVar', 'SqFt1stFloor', 'SqFtHalfFloor', 'SqFt2ndFloor',\n",
    "                           'SqFtUpperFloor', 'SqFtUnfinFull', 'SqFtUnfinHalf', 'SqFtTotLiving', 'SqFtTotBasement', \n",
    "                           'SqFtFinBasement', 'FinBasementGrade', 'SqFtGarageBasement', 'SqFtGarageAttached', \n",
    "                           'DaylightBasement','SqFtOpenPorch', 'SqFtEnclosedPorch', 'SqFtDeck', 'HeatSystem',\n",
    "                           'HeatSource', 'BrickStone', 'ViewUtilization', 'Bedrooms','BathHalfCount', \n",
    "                           'Bath3qtrCount', 'BathFullCount', 'FpSingleStory','FpMultiStory', 'FpFreestanding', \n",
    "                           'FpAdditional', 'YrBuilt','YrRenovated', 'PcntComplete', 'Obsolescence', \n",
    "                           'PcntNetCondition','Condition']\n",
    "rpsale_desired_columns = ['ExciseTaxNbr', 'Major', 'Minor', 'DocumentDate', 'SalePrice', 'RecordingNbr', 'PropertyType', \n",
    "                          'PrincipalUse', 'SaleInstrument', 'AFForestLand', 'AFCurrentUseLand', 'AFNonProfitUse', \n",
    "                          'AFHistoricProperty', 'SaleReason', 'PropertyClass', 'SaleWarning']\n",
    "\n",
    "# Remove all columns that are not in one of the above two lists.\n",
    "df_resbldg = df_resbldg[resbldg_desired_columns].copy()\n",
    "df_rpsale = df_rpsale[rpsale_desired_columns].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create identifier that will be used to connect the two dataframes. \n",
    "In this case, each database provides *Major* and *Minor*, which serve as location-specific identifiers. From here on, the combination of *Major* and *Minor* will simply be referred to as the *parcel*. Although there is often more than one sale associated with a parcel, this is a great place to start for narrowing down our search. The goal is to narrow down the *Sales* dataset to include only one sale per parcel. This allows for a connection with the second database, *Residential Buildings*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ParcelIDs\n",
    "df_rpsale['Parcel_ID'] = df_rpsale.Major + '-' + df_rpsale.Minor\n",
    "df_resbldg['Parcel_ID'] = df_resbldg.Major + '-' + df_resbldg.Minor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The *Sales* database: some of the nitty gritty data selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only sales for \"Residential\" plots, corresponding to code #6, as can be found in the data dictionary\n",
    "# This eliminates Commerical, Condominium, Apartment, etc.\n",
    "df_rpsale['PrincipalUse'] = elimination_by_code(df_rpsale['PrincipalUse'], '6')\n",
    "\n",
    "# PropertyClass is another distinction between Commerical/Industrial and Residential, as well as \n",
    "# other fundamental features. Code #8 corresponds to Residential Improved property\n",
    "df_rpsale['PropertyClass'] = elimination_by_code(df_rpsale['PropertyClass'], '8')\n",
    "\n",
    "# Yet another classification of property type. Code #11 corresponds to single family households\n",
    "# Here we eliminate multiple family residences, alongside many commercial uses\n",
    "df_rpsale['PropertyType'] = elimination_by_code(df_rpsale['PropertyType'], '11')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Limit scope to 2019 sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type conversion\n",
    "df_rpsale['DocumentDate'] = df_rpsale.DocumentDate.astype(np.datetime64)\n",
    "\n",
    "# Isolate SaleYear as its own column\n",
    "df_rpsale['SaleYear'] = [sale.year for sale in df_rpsale['DocumentDate']]\n",
    "\n",
    "# Eliminate rows corresponding to sales in a year other than 2019\n",
    "df_rpsale = df_rpsale.loc[df_rpsale['SaleYear']==2019].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Eliminate unrealistically small sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_acceptable_sale_price = 25000\n",
    "df_rpsale['SalePrice'] = df_rpsale.SalePrice.astype('int')\n",
    "df_rpsale = df_rpsale.loc[df_rpsale.SalePrice > min_acceptable_sale_price].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create column to identify duplicates, a necessary process before combining the two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rpsale['SaleCount'] = list(map(dict(df_rpsale.Parcel_ID.value_counts()).get, df_rpsale.Parcel_ID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
